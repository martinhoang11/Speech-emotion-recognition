{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import audioread\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from sys import byteorder\n",
    "from array import array\n",
    "from struct import pack\n",
    "\n",
    "import wave\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#To find the duration of wave file in seconds\n",
    "import wave\n",
    "import contextlib\n",
    "\n",
    "#Keras imports\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absoluteFilePaths(directory):\n",
    "    for dirpath,_,filenames in os.walk(directory):\n",
    "        for f in filenames:\n",
    "            yield os.path.abspath(os.path.join(dirpath, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation:\n",
    "    def read_audio_file(self, file_path):\n",
    "            input_length = 36000\n",
    "            data = librosa.core.load(file_path)[0]\n",
    "            if len(data) > input_length:\n",
    "                data = data[:input_length]\n",
    "            else:\n",
    "                data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "            return data\n",
    "        \n",
    "    def dyn_change(self, data):\n",
    "        \"\"\"\n",
    "        Random Value Change.\n",
    "        \"\"\"\n",
    "        dyn_change = np.random.uniform(low=1.5,high=3)\n",
    "        return (data * dyn_change)\n",
    "    \n",
    "    def pitch_adv(data, sample_rate):\n",
    "        \"\"\"\n",
    "        Pitch Tuning.\n",
    "        \"\"\"\n",
    "        bins_per_octave = 12\n",
    "        pitch_pm = 2\n",
    "        pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
    "        data = librosa.effects.pitch_shift(data.astype('float64'), \n",
    "                                          sample_rate, n_steps=pitch_change, \n",
    "                                          bins_per_octave=bins_per_octave)\n",
    "\n",
    "    \n",
    "    def shift_adv(self, data):\n",
    "        \"\"\"\n",
    "        Random Shifting.\n",
    "        \"\"\"\n",
    "        s_range = int(np.random.uniform(low=-5, high = 5)*500)\n",
    "        return np.roll(data, s_range)\n",
    "    \n",
    "    def noise_adv(self, data):\n",
    "        \"\"\"\n",
    "        Adding White Noise.\n",
    "        \"\"\"\n",
    "        # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
    "        noise_amp = 0.005*np.random.uniform()*np.amax(data)\n",
    "        data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
    "        return data\n",
    "    \n",
    "    def add_noise(self, data):\n",
    "        noise = np.random.randn(len(data))\n",
    "        data_noise = data + 0.005*noise\n",
    "        return data_noise\n",
    "\n",
    "    def shift(self, data):\n",
    "        return np.roll(data, 1600)\n",
    "\n",
    "    def stretch(self, data, rate=0.8): #0.8\n",
    "        input_length = 36000\n",
    "        data = librosa.effects.time_stretch(data, rate)\n",
    "        if len(data) > input_length:\n",
    "            data = data[:input_length]\n",
    "        else:\n",
    "            data = np.pad(data, (0, max(0, input_length - len(data))), \"constant\")\n",
    "        return data\n",
    "\n",
    "    def pitch(self, data):\n",
    "        return librosa.effects.pitch_shift(data, 16000, 0.9)\n",
    "\n",
    "    def speed(self, data):\n",
    "        return librosa.effects.time_stretch(data, 1.5)\n",
    "\n",
    "    def write_audio_file(self, file, data, sample_rate=16000):\n",
    "        librosa.output.write_wav(file, data, sample_rate)\n",
    "\n",
    "    def plot_time_series(self, data):\n",
    "        fig = plt.figure(figsize=(14, 8))\n",
    "        plt.title('Raw wave ')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.plot(np.linspace(0, 1, len(data)), data)\n",
    "        plt.show()\n",
    "\n",
    "    def get_dur(self, file):\n",
    "        with audioread.audio_open(file) as f:\n",
    "            return f.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_spectrogram(in_path, out_path, mode=None, nfft=512, noverlap=511):\n",
    "    rate, data = wavfile.read(in_path)\n",
    "    aa = Augmentation()\n",
    "    #print(\"\")\n",
    "    if mode == 'stretch':\n",
    "        data = aa.stretch(data)\n",
    "    elif mode == 'pitch':\n",
    "        data = aa.pitch(data)\n",
    "    elif mode == 'noise':\n",
    "        data = aa.noise_adv(data)\n",
    "    elif mode == 'shift':\n",
    "        data = aa.shift_adv(data)\n",
    "    elif mode == 'speed':\n",
    "        data = aa.speed(data)    \n",
    "    elif mode == 'defaut':\n",
    "        data = data\n",
    "    fig,ax = plt.subplots(1)\n",
    "    fig.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    ax.axis('off')\n",
    "    pxx, freqs, bins, im = ax.specgram(x=data, Fs=rate, noverlap=noverlap, NFFT=nfft)\n",
    "    ax.axis('off')\n",
    "    plt.rcParams['figure.figsize'] = [0.75,0.5]\n",
    "    file_name = in_path.split(\"/\")[-1].split(\".\")[0] + '_{}'.format(mode)\n",
    "    out_img = \"/home/bigbrain/emotion-recognize/images/Train1/\"\n",
    "    des_path  = out_img + file_name + \".png\"\n",
    "    plt.savefig(des_path, dpi=300, frameon='false')\n",
    "    fig.canvas.draw()\n",
    "    size_inches  = fig.get_size_inches()\n",
    "    dpi          = fig.get_dpi()\n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "\n",
    "    #print(size_inches, dpi, width, height)\n",
    "    mplimage = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    #print(\"MPLImage Shape: \", np.shape(mplimage))\n",
    "    imarray = np.reshape(mplimage, (int(height), int(width), 3))\n",
    "    plt.close(fig)\n",
    "    del file_name,des_path,data,rate,fig,ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spectrogram from .wav file PAEP-000001.wav\n",
    "def create_spectrogram(in_path, out_path, mode='defaut'):\n",
    "    aa = Augmentation()\n",
    "    \n",
    "    plt.interactive(False)\n",
    "    clip, sample_rate = librosa.load(in_path, sr=16000)\n",
    "    \n",
    "    if mode == 'stretch':\n",
    "        clip = aa.stretch(clip)\n",
    "    elif mode == 'pitch':\n",
    "        clip = aa.pitch(clip)\n",
    "    elif mode == 'noise':\n",
    "        clip = aa.add_noise(clip)\n",
    "    elif mode == 'shift':\n",
    "        clip = aa.shift(clip)\n",
    "    elif mode == 'speed':\n",
    "        clip = aa.speed(clip)    \n",
    "    elif mode == 'defaut':\n",
    "        clip = clip\n",
    "        \n",
    "    fig = plt.figure(figsize=[0.72,0.72])\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    S = librosa.feature.melspectrogram(y=clip, sr=sample_rate)\n",
    "    librosa.display.specshow(librosa.power_to_db(S, ref=np.max))\n",
    "    file_name = in_path.split(\"/\")[-1].split(\".\")[0] + '_{}'.format(mode)\n",
    "    out_img = \"/home/bigbrain/emotion-recognize/images/Train1/\"\n",
    "    des_path  = out_img + file_name + \".png\"\n",
    "    plt.savefig(des_path, dpi=400, bbox_inches='tight',pad_inches=0)\n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    plt.close('all')\n",
    "    aa.write_audio_file(out_path + '{}.wav'.format(file_name), clip)\n",
    "    del file_name,des_path,clip,sample_rate,fig,ax,S\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(absoluteFilePaths('/home/bigbrain/emotion-recognize/Handout/Train1/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5229/5229 [20:25<00:00,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_file = \"/home/bigbrain/emotion-recognize/Handout/Train1/\"\n",
    "\n",
    "for file in tqdm(files):\n",
    "    create_spectrogram(file, target_file, mode=\"noise\")\n",
    "    create_spectrogram(file, target_file, \"stretch\")\n",
    "#     create_spectrogram(file, target_file, \"pitch\")\n",
    "#     create_spectrogram(file, target_file, \"speed\")\n",
    "    create_spectrogram(file, target_file, mode=\"shift\")\n",
    "    create_spectrogram(file, target_file, mode='defaut')\n",
    "print(\"Done!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_audio = pd.read_csv('../Handout/train_label.csv')\n",
    "# data_audio.File = data_audio.File.str.replace('.png','.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PAEP-000001.wav</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAEP-000002.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAEP-000003.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAEP-000004.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PAEP-000005.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5224</th>\n",
       "      <td>PAEP-005225.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5225</th>\n",
       "      <td>PAEP-005226.wav</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>PAEP-005227.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5227</th>\n",
       "      <td>PAEP-005228.wav</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5228</th>\n",
       "      <td>PAEP-005229.wav</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5229 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 File  Label\n",
       "0     PAEP-000001.wav      3\n",
       "1     PAEP-000002.wav      5\n",
       "2     PAEP-000003.wav      4\n",
       "3     PAEP-000004.wav      1\n",
       "4     PAEP-000005.wav      0\n",
       "...               ...    ...\n",
       "5224  PAEP-005225.wav      0\n",
       "5225  PAEP-005226.wav      2\n",
       "5226  PAEP-005227.wav      1\n",
       "5227  PAEP-005228.wav      4\n",
       "5228  PAEP-005229.wav      5\n",
       "\n",
       "[5229 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns={'File', 'Label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files = list(absoluteFilePaths('/home/bigbrain/emotion-recognize/Handout/Train1/'))\n",
    "for file in files:\n",
    "    file = file.split('/')[-1]\n",
    "    df = df.append({'File': file, 'Label': 'x'}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-004667_noise.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-002135.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-003204.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-001005_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-004512_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-004048_noise.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-002564_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-001220.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-003784.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>x</td>\n",
       "      <td>PAEP-000588.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15687 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                   File\n",
       "0         x  PAEP-004667_noise.wav\n",
       "1         x        PAEP-002135.wav\n",
       "2         x        PAEP-003204.wav\n",
       "3         x  PAEP-001005_shift.wav\n",
       "4         x  PAEP-004512_shift.wav\n",
       "...     ...                    ...\n",
       "15682     x  PAEP-004048_noise.wav\n",
       "15683     x  PAEP-002564_shift.wav\n",
       "15684     x        PAEP-001220.wav\n",
       "15685     x        PAEP-003784.wav\n",
       "15686     x        PAEP-000588.wav\n",
       "\n",
       "[15687 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bigbrain/emotion-recognize/emr/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: `item` has been deprecated and will be removed in a future version\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in df['File']:\n",
    "    i = i.split('.')[0].split('_')[0] + \".wav\"\n",
    "    label = data_audio[data_audio[\"File\"] == i][\"Label\"].item()\n",
    "    array.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>PAEP-004667_noise.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>PAEP-002135.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PAEP-003204.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>PAEP-001005_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>PAEP-004512_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>2</td>\n",
       "      <td>PAEP-004048_noise.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>4</td>\n",
       "      <td>PAEP-002564_shift.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>3</td>\n",
       "      <td>PAEP-001220.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>2</td>\n",
       "      <td>PAEP-003784.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>0</td>\n",
       "      <td>PAEP-000588.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15687 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Label                   File\n",
       "0          5  PAEP-004667_noise.wav\n",
       "1          3        PAEP-002135.wav\n",
       "2          3        PAEP-003204.wav\n",
       "3          5  PAEP-001005_shift.wav\n",
       "4          0  PAEP-004512_shift.wav\n",
       "...      ...                    ...\n",
       "15682      2  PAEP-004048_noise.wav\n",
       "15683      4  PAEP-002564_shift.wav\n",
       "15684      3        PAEP-001220.wav\n",
       "15685      2        PAEP-003784.wav\n",
       "15686      0        PAEP-000588.wav\n",
       "\n",
       "[15687 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../Handout/train_last.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
